{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, argparse\n",
    "\n",
    "# from calendar import calendar\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "# from pathlib import Path\n",
    "# from sqlalchemy import create_engine\n",
    "import geopandas as gpd\n",
    "import geoalchemy2\n",
    "from io import StringIO\n",
    "import zipfile\n",
    "import timeit\n",
    "import shutil\n",
    "\n",
    "from sqlalchemy import create_engine,MetaData\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from shapely.geometry import Point\n",
    "\n",
    "\n",
    "debug = True\n",
    "local = True\n",
    "# from sqlalchemy.orm import Session,sessionmaker\n",
    "# from config import Config\n",
    "# from .database_connector import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting zip file to temp directory: ../lacmta//future/gtfs_bus-copy.zip\n",
      "Error getting latest modified zip file: [WinError 3] The system cannot find the path specified: '../lacmta-rail//future'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 43\u001b[0m, in \u001b[0;36mget_latest_modified_zip_file\u001b[1;34m(path, folder_branch)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 43\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmax\u001b[39m([target_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mf \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(target_path) \u001b[39mif\u001b[39;00m f\u001b[39m.\u001b[39mendswith(\u001b[39m'\u001b[39m\u001b[39m.zip\u001b[39m\u001b[39m'\u001b[39m)], key\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mgetmtime)\n\u001b[0;32m     44\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '../lacmta-rail//future'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[9], line 281\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__main__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 281\u001b[0m     main()\n\u001b[0;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m debug \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[9], line 256\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    255\u001b[0m process_zip_files_for_agency_id(\u001b[39m'\u001b[39m\u001b[39mlacmta\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 256\u001b[0m process_zip_files_for_agency_id(\u001b[39m'\u001b[39;49m\u001b[39mlacmta-rail\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    257\u001b[0m update_gtfs_static_files()\n",
      "Cell \u001b[1;32mIn[9], line 63\u001b[0m, in \u001b[0;36mprocess_zip_files_for_agency_id\u001b[1;34m(agency_id)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[39mif\u001b[39;00m local:\n\u001b[1;32m---> 63\u001b[0m     target_zip_files \u001b[39m=\u001b[39m get_latest_modified_zip_file(\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m../lacmta-rail/\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mfuture\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[9], line 46\u001b[0m, in \u001b[0;36mget_latest_modified_zip_file\u001b[1;34m(path, folder_branch)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mError getting latest modified zip file: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(e))\n\u001b[1;32m---> 46\u001b[0m sys\u001b[39m.\u001b[39;49mexit(\u001b[39m1\u001b[39;49m)\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py:2095\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2092\u001b[0m \u001b[39mif\u001b[39;00m exception_only:\n\u001b[0;32m   2093\u001b[0m     stb \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mAn exception has occurred, use \u001b[39m\u001b[39m%\u001b[39m\u001b[39mtb to see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   2094\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mthe full traceback.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m]\n\u001b[1;32m-> 2095\u001b[0m     stb\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mInteractiveTB\u001b[39m.\u001b[39;49mget_exception_only(etype,\n\u001b[0;32m   2096\u001b[0m                                                      value))\n\u001b[0;32m   2097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2098\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2099\u001b[0m         \u001b[39m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2100\u001b[0m         \u001b[39m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2101\u001b[0m         \u001b[39m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:710\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_exception_only\u001b[39m(\u001b[39mself\u001b[39m, etype, value):\n\u001b[0;32m    703\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \n\u001b[0;32m    705\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[39m    value : exception value\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 710\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39;49mstructured_traceback(\u001b[39mself\u001b[39;49m, etype, value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:568\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    565\u001b[0m     chained_exc_ids\u001b[39m.\u001b[39madd(\u001b[39mid\u001b[39m(exception[\u001b[39m1\u001b[39m]))\n\u001b[0;32m    566\u001b[0m     chained_exceptions_tb_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    567\u001b[0m     out_list \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 568\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m    569\u001b[0m             etype,\n\u001b[0;32m    570\u001b[0m             evalue,\n\u001b[0;32m    571\u001b[0m             (etb, chained_exc_ids),  \u001b[39m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    572\u001b[0m             chained_exceptions_tb_offset,\n\u001b[0;32m    573\u001b[0m             context,\n\u001b[0;32m    574\u001b[0m         )\n\u001b[0;32m    575\u001b[0m         \u001b[39m+\u001b[39m chained_exception_message\n\u001b[0;32m    576\u001b[0m         \u001b[39m+\u001b[39m out_list)\n\u001b[0;32m    578\u001b[0m \u001b[39mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:1428\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1426\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1427\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtb \u001b[39m=\u001b[39m etb\n\u001b[1;32m-> 1428\u001b[0m \u001b[39mreturn\u001b[39;00m FormattedTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1429\u001b[0m     \u001b[39mself\u001b[39;49m, etype, evalue, etb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1430\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:1319\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1316\u001b[0m mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\n\u001b[0;32m   1317\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose_modes:\n\u001b[0;32m   1318\u001b[0m     \u001b[39m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1319\u001b[0m     \u001b[39mreturn\u001b[39;00m VerboseTB\u001b[39m.\u001b[39;49mstructured_traceback(\n\u001b[0;32m   1320\u001b[0m         \u001b[39mself\u001b[39;49m, etype, value, tb, tb_offset, number_of_lines_of_context\n\u001b[0;32m   1321\u001b[0m     )\n\u001b[0;32m   1322\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mMinimal\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m   1323\u001b[0m     \u001b[39mreturn\u001b[39;00m ListTB\u001b[39m.\u001b[39mget_exception_only(\u001b[39mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:1172\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstructured_traceback\u001b[39m(\n\u001b[0;32m   1164\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1165\u001b[0m     etype: \u001b[39mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     number_of_lines_of_context: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m,\n\u001b[0;32m   1170\u001b[0m ):\n\u001b[0;32m   1171\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1172\u001b[0m     formatted_exception \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mformat_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m   1173\u001b[0m                                                            tb_offset)\n\u001b[0;32m   1175\u001b[0m     colors \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mColors  \u001b[39m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1176\u001b[0m     colorsnormal \u001b[39m=\u001b[39m colors\u001b[39m.\u001b[39mNormal  \u001b[39m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:1062\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(tb_offset, \u001b[39mint\u001b[39m)\n\u001b[0;32m   1060\u001b[0m head \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprepare_header(\u001b[39mstr\u001b[39m(etype), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlong_header)\n\u001b[0;32m   1061\u001b[0m records \u001b[39m=\u001b[39m (\n\u001b[1;32m-> 1062\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_records(etb, number_of_lines_of_context, tb_offset) \u001b[39mif\u001b[39;00m etb \u001b[39melse\u001b[39;00m []\n\u001b[0;32m   1063\u001b[0m )\n\u001b[0;32m   1065\u001b[0m frames \u001b[39m=\u001b[39m []\n\u001b[0;32m   1066\u001b[0m skipped \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py:1130\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1128\u001b[0m \u001b[39mwhile\u001b[39;00m cf \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1129\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1130\u001b[0m         mod \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39mgetmodule(cf\u001b[39m.\u001b[39;49mtb_frame)\n\u001b[0;32m   1131\u001b[0m         \u001b[39mif\u001b[39;00m mod \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1132\u001b[0m             mod_name \u001b[39m=\u001b[39m mod\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "list_of_gtfs_static_files = [\"routes\", \"trips\", \"stops\", \"calendar\", \"shapes\",\"stop_times\"]\n",
    "\n",
    "# Argument parser for database connections\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Process database URI.')\n",
    "# parser.add_argument('--db_uri', metavar='db_uri', type=str, nargs='+',\n",
    "#                     help='The postgresql database URI for updating the GTFS Static data to.', required=True)\n",
    "\n",
    "# parser.add_argument('--db_schema', metavar='db_schema', type=str, nargs='+',help='Target postgresql database schema for updating.', required=True)\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "# DB_URI = args.db_uri[0]\n",
    "# TARGET_SCHEMA = args.db_schema[0]\n",
    "\n",
    "\n",
    "DB_URI = \"DB_URI\"\n",
    "TARGET_SCHEMA = \"metro_api_future\"\n",
    "\n",
    "engine = create_engine(DB_URI, echo=False)\n",
    "Session = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "\n",
    "session = Session()\n",
    "Base = declarative_base(metadata=MetaData(schema=TARGET_SCHEMA))\n",
    "\n",
    "df_to_combine = []\n",
    "\n",
    "\n",
    "def get_db():\n",
    "    db = Session()\n",
    "    try:\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "\n",
    "def get_latest_modified_zip_file(path,folder_branch):\n",
    "    target_path = path +\"/\" + folder_branch\n",
    "    if path is None:\n",
    "        print('No path provided.')\n",
    "        sys.exit(1)\n",
    "    try:\n",
    "        return max([target_path+'/'+f for f in os.listdir(target_path) if f.endswith('.zip')], key=os.path.getmtime)\n",
    "    except Exception as e:\n",
    "        print('Error getting latest modified zip file: ' + str(e))\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_zip_files_for_agency_id(agency_id):\n",
    "    target_zip_files = None\n",
    "    if agency_id is None:\n",
    "        print('No agency_id provided.')\n",
    "        sys.exit(1)\n",
    "    if agency_id == 'lacmta':\n",
    "        if local == True:\n",
    "            target_zip_files = get_latest_modified_zip_file(r'../lacmta/', 'future')\n",
    "        else:\n",
    "            target_zip_files = get_latest_modified_zip_file(r'./lacmta/', 'future')\n",
    "    if agency_id == 'lacmta-rail':\n",
    "        if local == True:\n",
    "            target_zip_files = get_latest_modified_zip_file(r'../lacmta-rail/', 'future')\n",
    "        else:\n",
    "            target_zip_files = get_latest_modified_zip_file(r'./lacmta-rail/', 'current')\n",
    "    extract_zip_file_to_temp_directory(target_zip_files,agency_id)\n",
    "\n",
    "def extract_zip_file_to_temp_directory(zip_file,agency_id):\n",
    "    try:\n",
    "        print('Extracting zip file to temp directory: ' + zip_file)\n",
    "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall('./temp/'+agency_id)\n",
    "    except Exception as e:\n",
    "        print('Error extracting zip file to temp directory: ' + str(e))\n",
    "        sys.exit(1)\n",
    "\n",
    "#### END FILE EXTRACTION ####\n",
    "\n",
    "#### START GTFS STATIC PROCESSING ####\n",
    "def update_gtfs_static_files():\n",
    "    global stop_times_df\n",
    "    global trips_df\n",
    "    global calendar_dates_df\n",
    "    global calendar_df\n",
    "    global stops_df\n",
    "    for file in list_of_gtfs_static_files:\n",
    "        print(\"******************\")\n",
    "        print(\"Starting with \" + file)\n",
    "        process_start = timeit.default_timer()\n",
    "        bus_file_path = \"\"\n",
    "        rail_file_path = \"\"\n",
    "        bus_file_path = \"./temp/lacmta/\" + file + '.txt'\n",
    "        rail_file_path = \"./temp/lacmta-rail/\" + file + '.txt'\n",
    "        temp_df_bus = pd.read_csv(bus_file_path)\n",
    "        temp_df_bus['agency_id'] = 'LACMTA'\n",
    "        temp_df_rail = pd.read_csv(rail_file_path)\n",
    "        temp_df_rail['agency_id'] = 'LACMTA_Rail'\n",
    "        if file == \"stops\":\n",
    "            stops_df = update_stops_seperately(temp_df_bus,temp_df_rail,file)\n",
    "        elif file == \"shapes\":\n",
    "            temp_gdf_bus = gpd.GeoDataFrame(temp_df_bus, geometry=gpd.points_from_xy(temp_df_bus.shape_pt_lon, temp_df_bus.shape_pt_lat))   \n",
    "            temp_gdf_rail = gpd.GeoDataFrame(temp_df_rail, geometry=gpd.points_from_xy(temp_df_rail.shape_pt_lon, temp_df_rail.shape_pt_lat))\n",
    "            shapes_combined_gdf = gpd.GeoDataFrame(pd.concat([temp_gdf_bus, temp_gdf_rail],ignore_index=True),geometry='geometry')\n",
    "            shapes_combined_gdf.crs = 'EPSG:4326'\n",
    "            if debug == False:\n",
    "                shapes_combined_gdf.to_postgis(file,engine,index=False,if_exists=\"replace\",schema=TARGET_SCHEMA)\n",
    "        else:\n",
    "            combined_temp_df = pd.concat([temp_df_bus, temp_df_rail])\n",
    "            if file == \"stop_times\":\n",
    "                stop_times_df = combined_temp_df\n",
    "            if file == \"trips\":\n",
    "                trips_df = combined_temp_df\n",
    "            if file == \"calendar_dates\":\n",
    "                calendar_dates_df = combined_temp_df\n",
    "            if file == \"calendar\":\n",
    "                calendar_df = combined_temp_df\n",
    "            if debug == False:\n",
    "                combined_temp_df.to_sql(file,engine,index=False,if_exists=\"replace\",schema=TARGET_SCHEMA)\n",
    "        process_end = timeit.default_timer()\n",
    "        \n",
    "        with open('logs.txt', 'a+') as f:\n",
    "            human_readable_date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            total_time = process_end - process_start\n",
    "            total_time_rounded = round(total_time,2)\n",
    "            print(human_readable_date+\" | \" + file + \" | \" + str(total_time_rounded) + \" seconds.\", file=f)\n",
    "            print(\"Done with \" + file)\n",
    "            print(\"******************\")\n",
    " \n",
    "\n",
    "def get_lat_long_from_coordinates(geojson):\n",
    "    this_geojson_geom = geojson['geometry']\n",
    "    return Point(this_geojson_geom['coordinates'][0], this_geojson_geom['coordinates'][1])\n",
    "\n",
    "\n",
    "\n",
    "def get_stop_times_from_stop_id(this_row):\n",
    "    # print('Getting stop times for stop id')\n",
    "    trips_by_route_df = trips_df.loc[trips_df['route_id'] == this_row.route_id]\n",
    "    \n",
    "    stop_times_by_trip_df = stop_times_df[stop_times_df['trip_id'].isin(trips_by_route_df['trip_id'])]\n",
    "\n",
    "    # get the stop times for this stop id\n",
    "    this_stops_df = stop_times_by_trip_df.loc[stop_times_by_trip_df['stop_id'] == this_row.stop_id]\n",
    "    this_stops_df = this_stops_df.sort_values(by=['departure_time'],ascending=True)\n",
    "    # simplified_this_stops_df = simplified_this_stops_df.to_json(orient='records')\n",
    "\n",
    "    departure_times_array = this_stops_df['departure_time'].values.tolist()\n",
    "    # to check:\n",
    "    # print(simplified_this_stops_df)\n",
    "\n",
    "    # combined_stop_times_array.append(simplified_this_stops_df)\n",
    "    return departure_times_array\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "def update_stops_seperately(temp_df_bus,temp_df_rail,file):\n",
    "    # temp_df_bus['geometry'] = [Point(xy) for xy in zip(temp_df_bus.stop_lon, temp_df_bus.stop_lat)] \n",
    "    temp_df_bus['agency_id'] = 'LACMTA'\n",
    "    temp_gdf_bus_stops = gpd.GeoDataFrame(temp_df_bus,geometry=gpd.points_from_xy(temp_df_bus.stop_lon, temp_df_bus.stop_lat))\n",
    "    temp_gdf_bus_stops.set_crs(epsg=4326, inplace=True)\n",
    "\n",
    "    # temp_df_rail['geometry'] = [Point(xy) for xy in zip(temp_df_rail.stop_lon, temp_df_rail.stop_lat)] \n",
    "    temp_df_rail['agency_id'] = 'LACMTA_Rail'\n",
    "    temp_gdf_bus_stops['stop_id'] = temp_gdf_bus_stops['stop_id'].astype('str')\n",
    "    temp_gdf_bus_stops['stop_code'] = temp_gdf_bus_stops['stop_code'].astype('str')\n",
    "    temp_gdf_bus_stops['parent_station'] = temp_gdf_bus_stops['parent_station'].astype('str')\n",
    "    temp_gdf_bus_stops['tpis_name'] = temp_gdf_bus_stops['tpis_name'].astype('str')\n",
    "\n",
    "    temp_gdf_rail_stops = gpd.GeoDataFrame(temp_df_rail,geometry=gpd.points_from_xy(temp_df_rail.stop_lon, temp_df_rail.stop_lat))\n",
    "    temp_gdf_rail_stops.set_crs(epsg=4326, inplace=True)\n",
    "    temp_gdf_rail_stops['stop_id'] = temp_gdf_rail_stops['stop_id'].astype('str')\n",
    "    temp_gdf_rail_stops['stop_code'] = temp_gdf_rail_stops['stop_code'].astype('str')\n",
    "    temp_gdf_rail_stops['parent_station'] = temp_gdf_rail_stops['parent_station'].astype('str')\n",
    "    temp_gdf_rail_stops['tpis_name'] = temp_gdf_rail_stops['tpis_name'].astype('str')\n",
    "    if debug == False:\n",
    "        temp_gdf_rail_stops.to_postgis(\"stops\",engine,schema=TARGET_SCHEMA,if_exists=\"replace\",index=False)\n",
    "        temp_gdf_bus_stops.to_postgis(\"stops\",engine,schema=TARGET_SCHEMA,if_exists=\"append\",index=False)\n",
    "    return pd.concat([temp_gdf_bus_stops,temp_gdf_rail_stops])\n",
    "    \n",
    "\n",
    "#### TRIP CREATION ####\n",
    "\n",
    "def get_day_type_from_service_id(row):\n",
    "    # print('Getting day type from service id')\n",
    "    cleaned_row = str(row).lower()\n",
    "    if 'weekday' in cleaned_row:\n",
    "        return 'weekday'\n",
    "    elif 'saturday' in cleaned_row:\n",
    "        return 'saturday'\n",
    "    elif 'sunday' in cleaned_row:\n",
    "        return 'sunday'\n",
    "\n",
    "def get_day_type_from_trip_id(trip_id):\n",
    "    # print('Getting day type from trip id')\n",
    "   this_service_id = trips_df.loc[trips_df['trip_id'] == trip_id, 'service_id'].iloc[0]\n",
    "   return get_day_type_from_service_id(this_service_id)\n",
    "\n",
    "def create_list_of_trips(trips,stop_times):\n",
    "    print('Creating list of trips')\n",
    "    global trips_list_df\n",
    "    # stop_times['day_type'] = stop_times['trip_id_event'].map(get_day_type_from_service_id)\n",
    "    # stop_times['day_type'] = stop_times['day_type'].fillna(stop_times['trip_id'].map(get_day_type_from_trip_id))\n",
    "    trips_list_df = stop_times.groupby('trip_id')['stop_sequence'].max().sort_values(ascending=False).reset_index()\n",
    "    trips_list_df = trips_list_df.merge(stop_times[['trip_id','stop_id','stop_sequence','route_code']], on=['trip_id','stop_sequence'])\n",
    "    summarized_trips_df = trips[[\"route_id\",\"trip_id\",\"direction_id\",\"service_id\",\"agency_id\"]]\n",
    "    summarized_trips_df['day_type'] = summarized_trips_df['service_id'].map(get_day_type_from_service_id)\n",
    "    trips_list_df = trips_list_df.merge(summarized_trips_df, on='trip_id').drop_duplicates(subset=['route_id','day_type','direction_id'])\n",
    "    # trips_list_df.to_csv('trips_list_df.csv')\n",
    "\n",
    "\n",
    "def encode_lat_lon_to_geojson(lat,lon):\n",
    "    this_geojson = {\n",
    "        \"type\":\"Feature\",\n",
    "        \"geometry\":{\n",
    "            \"type\":\"Point\",\n",
    "            \"coordinates\": [lon,lat]\n",
    "        }\n",
    "    }\n",
    "    return this_geojson\n",
    "\n",
    "\n",
    "def get_stops_data_based_on_stop_id(stop_id):\n",
    "    # print('Getting stops data based on stop id')\n",
    "    this_stops_df = stops_df.loc[stops_df['stop_id'] == str(stop_id)]\n",
    "    # print(this_stops_df[['stop_name','stop_lat','stop_lon']])\n",
    "    # new_object = this_stops_df[['stop_name','stop_lat','stop_lon']].to_dict('records')\n",
    "    new_object = encode_lat_lon_to_geojson(this_stops_df['stop_lat'].values[0],this_stops_df['stop_lon'].values[0])\n",
    "    # print('stop_id',stop_id)\n",
    "    return new_object\n",
    "\n",
    "\n",
    "def get_stop_times_for_trip_id(this_row):\n",
    "    this_trips_df = stop_times_df.loc[stop_times_df['trip_id'] == this_row.trip_id]\n",
    "    this_trips_df['route_id'] = this_row.route_id\n",
    "    # this_trips_df['service_id'] = this_row.service_id\n",
    "    this_trips_df['direction_id'] = this_row.direction_id\n",
    "    this_trips_df['day_type'] = this_row.day_type\n",
    "    this_trips_df['geojson'] = this_trips_df.apply(lambda x: get_stops_data_based_on_stop_id(x.stop_id),axis=1)\n",
    "    this_trips_df['stop_name'] = this_trips_df.apply(lambda x: stops_df.loc[stops_df['stop_id'] == str(x.stop_id)]['stop_name'].values[0],axis=1)\n",
    "    # simplified_df = this_trips_df[['route_id','stop_id','service_id','day_type','direction_id','stop_name','coordinates']]\n",
    "    simplified_df = this_trips_df[['route_id','route_code','stop_id','day_type','stop_sequence','direction_id','stop_name','geojson','agency_id']]\n",
    "    \n",
    "    df_to_combine.append(simplified_df)\n",
    "    return simplified_df\n",
    "\n",
    "\n",
    "def main():\n",
    "    if DB_URI is None:\n",
    "        print('No database URI provided.')\n",
    "        sys.exit(1)\n",
    "    if TARGET_SCHEMA is None:\n",
    "        print('No database schema provided.')\n",
    "        sys.exit(1)\n",
    "    process_zip_files_for_agency_id('lacmta')\n",
    "    process_zip_files_for_agency_id('lacmta-rail')\n",
    "    update_gtfs_static_files()\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def remove_temp_files():\n",
    "    temp_directory = os.path.join(os.getcwd(),'temp')\n",
    "    if os.path.exists(temp_directory):\n",
    "        shutil.rmtree(temp_directory)\n",
    "    else:\n",
    "        print(\"The temp  does not exist\")\n",
    "\n",
    "def commit_logs_to_github_repo():\n",
    "    try:\n",
    "        print('Committing logs to github repo')\n",
    "        # os.system('git checkout logs')\n",
    "        os.system('git add .')\n",
    "        os.system('git commit -m \"Updated logs on '+str(datetime.datetime.now()))\n",
    "        os.system('git push origin logs')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    if debug == False:\n",
    "        commit_logs_to_github_repo()\n",
    "    remove_temp_files()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   create_list_of_trips(trips_df,stop_times_df)\n",
    "\n",
    "\n",
    "    trips_list_df.apply(lambda row: get_stop_times_for_trip_id(row), axis=1)\n",
    "    stop_times_by_route_df = pd.concat(df_to_combine)\n",
    "    stop_times_by_route_df['departure_times'] = stop_times_by_route_df.apply(lambda row: get_stop_times_from_stop_id(row),axis=1)\n",
    "    stop_times_by_route_df['route_code'].fillna(stop_times_by_route_df['route_id'], inplace=True)\n",
    "    print(\"Processing route stops...\")\n",
    "    process_start = timeit.default_timer()\n",
    "    route_stops_geo_data_frame = gpd.GeoDataFrame(stop_times_by_route_df, geometry=stop_times_by_route_df.apply(lambda x: get_lat_long_from_coordinates(x.geojson),axis=1))\n",
    "    route_stops_geo_data_frame.set_crs(epsg=4326, inplace=True)\n",
    "    if debug == False:\n",
    "        # save to database\n",
    "        route_stops_geo_data_frame.to_postgis('route_stops',engine,index=False,if_exists=\"replace\",schema=TARGET_SCHEMA)\n",
    "    process_end = timeit.default_timer()\n",
    "    with open('logs.txt', 'a+') as f:\n",
    "        human_readable_date = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        total_time = process_end - process_start\n",
    "        total_time_rounded = round(total_time,2)\n",
    "        print(human_readable_date+\" | \" + \"route_stops\" + \" | \" + str(total_time_rounded) + \" seconds.\", file=f)\n",
    "    print(\"Done processing route stops.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('gis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8b53be3e7c868a69d45e9211cc2ba468bb716b43f6012815c0aa7a116865d41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
